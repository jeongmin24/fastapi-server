import os
import requests
import pandas as pd
import joblib
import numpy as np
from dateutil.relativedelta import relativedelta
from datetime import datetime, timedelta

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.multioutput import MultiOutputRegressor

# í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ê²½ë¡œ ìˆ˜ì • í•„ìš”
from app.common.fetch import fetch_api
from app.config.settings import GENERAL_KEY
from app.services.preprocessing import preprocess_stats_time_response

# ----------------------------------------------------------------------
# âš¡ï¸ í†µí•© ëª¨ë¸ í•™ìŠµ ìƒìˆ˜
# ----------------------------------------------------------------------
INTEGRATED_FEATURES = ["year", "month", "hour", "line_station"]  # í†µí•© ëª¨ë¸ì— ì‚¬ìš©í•  íŠ¹ì§•
TARGET_API_ROW_LIMIT = 1000  # API í˜¸ì¶œ ì‹œ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìµœëŒ€ í–‰ ìˆ˜ (ì„œìš¸ì‹œ API ê¸°ì¤€)


# ----------------------------------------------------------------------
# 1. ì§€ì›í•˜ëŠ” ëª¨ë“  ì—­/í˜¸ì„  ë¦¬ìŠ¤íŠ¸ êµ¬í•˜ê¸° (ìë™ ìˆ˜ì§‘)
# ----------------------------------------------------------------------
def get_all_active_stations() -> list[tuple[str, str]]:
    """
    APIë¥¼ í˜¸ì¶œí•˜ì—¬ í˜„ì¬ ìš´ì˜ ì¤‘ì¸ ëª¨ë“  ì—­ê³¼ í˜¸ì„  ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    # ğŸš¨ API ê²½ë¡œëŠ” ì‹¤ì œ ì§€í•˜ì²  ì—­ ì •ë³´ API ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì„œìš¸ì‹œ ì§€í•˜ì² ì—­ ì •ë³´ API (ì˜ˆì‹œ)
    url = f"http://openapi.seoul.go.kr:8088/{GENERAL_KEY}/json/SearchSTNBySubwayLineInfo/1/{TARGET_API_ROW_LIMIT}/"

    try:
        raw = fetch_api(url)
        rows = raw.get("SearchSTNBySubwayLineInfo", {}).get("row", [])
    except Exception as e:
        print(f"ğŸš¨ ì§€í•˜ì²  ì—­ ì •ë³´ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return []

    station_list = []

    for row in rows:
        line = row.get("LINE_NUM")  # ì˜ˆ: '2í˜¸ì„ '
        station = row.get("STN_NM")  # ì˜ˆ: 'ê°•ë‚¨'

        if line and station:
            # ì¼ë°˜ì ìœ¼ë¡œ 1í˜¸ì„ ~9í˜¸ì„ ê³¼ ê°™ì€ ì •ì‹ ë…¸ì„ ë§Œ í¬í•¨
            if line.replace("í˜¸ì„ ", "").isdigit() or line in ["ì‹ ë¶„ë‹¹ì„ ", "ê²½ì˜ì¤‘ì•™ì„ "]:
                station_list.append((line, station))

    # ì¤‘ë³µ ì œê±° (ì˜ˆ: ì„œìš¸ì—­ì€ ì—¬ëŸ¬ í˜¸ì„ ì— ì¡´ì¬í•˜ë¯€ë¡œ)
    unique_stations = sorted(list(set(station_list)))
    print(f"âœ… ì´ {len(unique_stations)}ê°œì˜ ê³ ìœ  ì—­/í˜¸ì„  ìŒ ìˆ˜ì§‘ ì™„ë£Œ.")
    return unique_stations


# ----------------------------------------------------------------------
# 2. ìµœê·¼ 6ê°œì›” ë¦¬ìŠ¤íŠ¸ êµ¬í•˜ê¸°
# ----------------------------------------------------------------------
def get_recent_months(n_months: int = 6) -> list[str]:
    today = datetime.today()
    months = [
        (today - relativedelta(months=i)).strftime("%Y%m")
        for i in range(n_months)
    ]
    print(f"âœ… ìˆ˜ì§‘í•  ì›” ëª©ë¡: {months}")
    return months


# 3. íŠ¹ì • ë‚ ì§œ ì§€í•˜ì²  ìŠ¹í•˜ì°¨ ì¸ì›ì„ JSON í˜•íƒœ -> pandas DataFrameìœ¼ë¡œ ë³€í™˜
def build_dataset_for_date(date: str, line: str = None, station: str = None):
    url = f"http://openapi.seoul.go.kr:8088/{GENERAL_KEY}/json/CardSubwayTime/1/{TARGET_API_ROW_LIMIT}/{date}"
    if line:
        url += f"/{line}"
    if station:
        url += f"/{station}"

    raw = fetch_api(url)
    rows = raw.get("CardSubwayTime", {}).get("row", [])
    df = pd.DataFrame(rows)
    return df


# ----------------------------------------------------------------------
# 4. í†µí•© ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸
# ----------------------------------------------------------------------
def train_integrated_model(months: list[str], target_stations: list[tuple[str, str]]):
    x_list = []
    y_list = []

    for line, station in target_stations:  # ëª¨ë“  ì—­/í˜¸ì„  ìŒì„ ìˆœíšŒ
        line_station_key = f"{line}_{station}"  # ê³ ìœ  í‚¤: 2í˜¸ì„ _ê°•ë‚¨

        for m in months:
            # print(f"ğŸ“… {m} [{line_station_key}] ë°ì´í„° ìˆ˜ì§‘ ì¤‘...") # ë¡œê·¸ê°€ ë„ˆë¬´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŒ

            # íŠ¹ì • ì—­ì˜ ë°ì´í„°ë§Œ APIë¡œ í˜¸ì¶œí•´ì„œ DataFrame ì–»ê¸° (API íš¨ìœ¨ì„ ìœ„í•´)
            df = build_dataset_for_date(m, line=line, station=station)

            if df.empty:
                continue

            for _, row in df.iterrows():
                results = preprocess_stats_time_response(row)
                if not results:
                    continue

                for x, y in results:  # ì‹œê°„ëŒ€ ë³„ë¡œ ë¶„í•´ëœ ìƒ˜í”Œë“¤
                    # ğŸš¨ íŠ¹ì§• í™•ì¥: ì—­/í˜¸ì„  íŠ¹ì§• ì¶”ê°€
                    x['line_station'] = line_station_key
                    x_list.append(x)
                    y_list.append(y)

    # DataFrame ìƒì„± ë° One-Hot Encoding ì ìš©
    x_combined = pd.DataFrame(x_list, columns=INTEGRATED_FEATURES)
    y = pd.DataFrame(y_list, columns=["gton", "gtoff"])

    # ğŸš¨ One-Hot Encoding ì ìš© ğŸš¨
    # 'line_station' ì»¬ëŸ¼ì„ OHEí•˜ì—¬ ëª¨ë“  ì—­ ì •ë³´ë¥¼ ìˆ˜ì¹˜í˜• íŠ¹ì§•ìœ¼ë¡œ ë³€í™˜
    X_final = pd.get_dummies(x_combined, columns=['line_station'], prefix='station')

    # í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¥¼ 8:2ë¡œ ë‚˜ëˆ”
    # OHE í›„ ì»¬ëŸ¼ ìˆ˜ê°€ í¬ê²Œ ì¦ê°€í•˜ë¯€ë¡œ, ë©”ëª¨ë¦¬ ê´€ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)

    print(f"ğŸ“Š ìµœì¢… í†µí•© í•™ìŠµ ë°ì´í„° í¬ê¸°: X={len(X_final)}, íŠ¹ì§•(ì»¬ëŸ¼) ìˆ˜: {len(X_final.columns)}")
    print(f"ğŸ“Š ìµœì¢… íƒ€ê²Ÿ ë°ì´í„° í¬ê¸°: Y={len(y)}")

    # MultiOutputRegressorë¡œ í•™ìŠµ ì§„í–‰
    model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, n_jobs=-1))  # n_jobs=-1ë¡œ ë³‘ë ¬ ì²˜ë¦¬
    model.fit(X_train, y_train)

    print("âœ… í†µí•© ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

    # ëª¨ë¸ í‰ê°€ ë° ì €ì¥
    evaluate_model(model, X_test, y_test)
    save_integrated_model(model, X_final.columns.tolist())  # íŠ¹ì§• ì»¬ëŸ¼ ëª©ë¡ë„ ì €ì¥ (ì˜ˆì¸¡ ì‹œ í•„ìš”)


# ----------------------------------------------------------------------
# 5. ëª¨ë¸ ì €ì¥ (ë‹¨ì¼ íŒŒì¼) ë° í‰ê°€
# ----------------------------------------------------------------------
def save_integrated_model(model, feature_columns: list[str]):
    # ì´ì œ ëª¨ë“  ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë‹´ì€ ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥
    os.makedirs("models", exist_ok=True)
    today = datetime.today().strftime("%Y%m%d")
    path = f"models/integrated_stats_model_{today}.pkl"

    # ëª¨ë¸ ê°ì²´ë¿ë§Œ ì•„ë‹ˆë¼, ì˜ˆì¸¡ ì‹œ OHEì— í•„ìš”í•œ íŠ¹ì§• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë„ í•¨ê»˜ ì €ì¥í•©ë‹ˆë‹¤.
    joblib.dump({
        'model': model,
        'feature_columns': feature_columns
    }, path)

    print(f"Model saved to {path}")


def evaluate_model(model, X_test, y_test):
    # ... (ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
    print("ğŸ” ëª¨ë¸ í‰ê°€ ì¤‘...")
    pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, pred))
    print(f"[{datetime.today()}] í†µí•© ëª¨ë¸ RMSE: {rmse:.2f}")

    os.makedirs("logs", exist_ok=True)
    with open("logs/eval.log", "a") as f:
        f.write(f"{datetime.today()} (Integrated) RMSE: {rmse:.2f}\n")


# ----------------------------------------------------------------------
# 6. ì‹¤í–‰ (Main)
# ----------------------------------------------------------------------
if __name__ == "__main__":
    print("ğŸ”¥ train.py ì‹œì‘ë¨: í†µí•© ëª¨ë¸ í•™ìŠµ ëª¨ë“œ")

    # 1. ëª¨ë“  ì—­/í˜¸ì„  ì •ë³´ ìë™ ìˆ˜ì§‘
    TARGET_STATIONS = get_all_active_stations()

    if not TARGET_STATIONS:
        print("ğŸš¨ ì˜¤ë¥˜: í•™ìŠµí•  ì—­ ì •ë³´ê°€ APIì—ì„œ ìˆ˜ì§‘ë˜ì§€ ì•Šì•„ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
    else:
        # 2. í†µí•© ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
        months = get_recent_months(n_months=6)
        train_integrated_model(months, TARGET_STATIONS)
import os
import pandas as pd
import joblib
import numpy as np
from dateutil.relativedelta import relativedelta

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from datetime import datetime, timedelta

from sklearn.multioutput import MultiOutputRegressor
from sklearn.preprocessing import LabelEncoder

# TODO: app.common.fetchì™€ app.config.settings ê²½ë¡œê°€ ë¡œì»¬ í™˜ê²½ì— ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
# Render í™˜ê²½ì—ì„œëŠ” API í˜¸ì¶œ ì‹œ GENERAL_KEYê°€ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
from app.common.fetch import fetch_api
from app.config.settings import GENERAL_KEY
from app.services.preprocessing import preprocess_stats_time_response


# 1. ìµœê·¼ Nê°œì›” ë¦¬ìŠ¤íŠ¸ êµ¬í•˜ê¸°
def get_recent_months(n_months: int = 6) -> list[str]:
    today = datetime.today()
    months = [
        (today - relativedelta(months=i)).strftime("%Y%m")
        for i in range(n_months)
    ]
    print(f"âœ… ìˆ˜ì§‘í•  ì›” ëª©ë¡: {months}")
    return months


# 2. íŠ¹ì • ë‚ ì§œ ì§€í•˜ì²  ìŠ¹í•˜ì°¨ ì¸ì›ì„ JSON í˜•íƒœ -> pandas DataFrameìœ¼ë¡œ ë³€í™˜
# API: ì„œìš¸ ì—´ë¦°ë°ì´í„° ê´‘ì¥ ì§€í•˜ì²  í˜¸ì„ ë³„ ì—­ë³„ ì‹œê°„ëŒ€ë³„ ìŠ¹ê° í˜„í™© ì¡°íšŒ
def build_dataset_for_date(date: str):
    # íŠ¹ì • ë…¸ì„ , ì—­ í•„í„° ì—†ì´ ìµœëŒ€ 1000ê°œì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
    url = f"http://openapi.seoul.go.kr:8088/{GENERAL_KEY}/json/CardSubwayTime/1/1000/{date}"
    raw = fetch_api(url)
    rows = raw.get("CardSubwayTime", {}).get("row", [])
    df = pd.DataFrame(rows)
    return df


# í•™ìŠµ ì „ì²´ íŒŒì´í”„ë¼ì¸ (ëª¨ë“  ì—­/í˜¸ì„  í†µí•© í•™ìŠµ)
def train_all_lines_and_stations(months: list[str]):
    all_dfs = []
    for m in months:
        print(f"ğŸ“… {m} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        # ëª¨ë“  ë…¸ì„ /ì—­ ë°ì´í„°ë¥¼ ë¡œë“œ
        df = build_dataset_for_date(m)

        if df.empty:
            print(f"âš ï¸ {m} ë°ì´í„° ì—†ìŒ. ê±´ë„ˆëœ”")
            continue
        print(f"â¡ï¸ {len(df)}ê°œì˜ í–‰ì´ ë¡œë“œë¨")
        all_dfs.append(df)

    if not all_dfs:
        print("ğŸš¨ í•™ìŠµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    master_df = pd.concat(all_dfs, ignore_index=True)

    # --- íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§: ë…¸ì„ ê³¼ ì—­ ì´ë¦„ì„ ìˆ«ìë¡œ ë³€í™˜ (Label Encoding) ---
    line_encoder = LabelEncoder()
    station_encoder = LabelEncoder()

    # ì‹¤ì œ ì»¬ëŸ¼ëª…
    LINE_COL = 'SBWY_ROUT_LN_NM'
    STATION_COL = 'STTN'

    print(f"ğŸ“Š master_df ì»¬ëŸ¼ ëª©ë¡: {master_df.columns.tolist()}")

    # 1. ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸ ë° ì—ëŸ¬ í•¸ë“¤ë§
    required_cols = [LINE_COL, STATION_COL]
    missing_cols = [col for col in required_cols if col not in master_df.columns]

    if missing_cols:
        print(f"âŒ DataFrameì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
        print("API ì‘ë‹µ ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.")
        return

    print(f"âœ… í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ: {LINE_COL}, {STATION_COL}")

    # 2. ê²°ì¸¡ì¹˜(NaN) ë°©ì§€ ë° ì¸ì½”ë”© ì‹¤í–‰
    master_df[LINE_COL] = master_df[LINE_COL].fillna('UnknownLine')
    master_df[STATION_COL] = master_df[STATION_COL].fillna('UnknownStation')

    master_df['LINE_NUM_ENCODED'] = line_encoder.fit_transform(master_df[LINE_COL])
    master_df['STATION_NAME_ENCODED'] = station_encoder.fit_transform(master_df[STATION_COL])

    print(f"âš™ï¸ ì´ {len(line_encoder.classes_)}ê°œ í˜¸ì„ , {len(station_encoder.classes_)}ê°œ ì—­ ì¸ì½”ë”© ì™„ë£Œ.")
    # -----------------------------------------------------------------

    x_list = []
    y_list = []

    # ì „ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì¸ì½”ë”©ëœ ê°’ë„ í•¨ê»˜ ì „ë‹¬
    for _, row in master_df.iterrows():
        row_with_encoded = row.to_dict()
        row_with_encoded['LINE_NUM_ENCODED'] = row['LINE_NUM_ENCODED']
        row_with_encoded['STATION_NAME_ENCODED'] = row['STATION_NAME_ENCODED']

        results = preprocess_stats_time_response(row_with_encoded)

        if not results:
            continue

        # ì‹œê°„ëŒ€ ë³„ ìƒ˜í”Œ (x, y)ë¥¼ ë¶„í•´í•˜ê³  ì¸ì½”ë”©ëœ íŠ¹ì§•ì„ xì— ì¶”ê°€
        line_enc = row['LINE_NUM_ENCODED']
        station_enc = row['STATION_NAME_ENCODED']

        for x_base, y in results:  # x_base = [year, month, hour]
            # ìµœì¢… ì…ë ¥ íŠ¹ì§•: [year, month, hour, line_encoded, station_encoded]
            x_final = x_base + [line_enc, station_enc]
            x_list.append(x_final)
            y_list.append(y)

    # x_list: ì…ë ¥ ë°ì´í„°(features)
    X_cols = ["year", "month", "hour", "line_encoded", "station_encoded"]
    y_cols = ["gton", "gtoff"]

    x = pd.DataFrame(x_list, columns=X_cols)
    y = pd.DataFrame(y_list, columns=y_cols)

    if x.empty:
        print("ğŸš¨ ì „ì²˜ë¦¬ í›„ í•™ìŠµ ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¥¼ 8:2ë¡œ ë‚˜ëˆ”
    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

    print(f"ğŸ“Š ìµœì¢… í•™ìŠµ ë°ì´í„° í¬ê¸°: X={len(x)}, Y={len(y)}")

    # MultiOutputRegressorë¡œ í•™ìŠµ ì§„í–‰ (RandomForestRegressorì— í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©)
    # n_estimators=50, max_depth=15 ì ìš©
    base_estimator = RandomForestRegressor(n_estimators=50, max_depth=15, random_state=42, n_jobs=-1)
    model = MultiOutputRegressor(base_estimator)
    model.fit(X_train, y_train)

    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    # ëª¨ë¸ í‰ê°€ ë° ì €ì¥
    evaluate_model(model, X_test, y_test)
    # ëª¨ë¸ê³¼ ì¸ì½”ë”ë¥¼ í•¨ê»˜ ì €ì¥
    save_model_and_encoders(model, line_encoder, station_encoder)


# ëª¨ë¸ ë° ì¸ì½”ë” ì €ì¥ (í•˜ë‚˜ì˜ pkl íŒŒì¼ë¡œ)
def save_model_and_encoders(model, line_encoder, station_encoder):
    today = datetime.today().strftime("%Y%m%d")
    os.makedirs("models", exist_ok=True)

    # ëª¨ë¸, ë…¸ì„  ì¸ì½”ë”, ì—­ ì¸ì½”ë”ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ í•˜ë‚˜ì˜ íŒŒì¼ì— ì €ì¥
    full_model_package = {
        "model": model,
        "line_encoder": line_encoder,
        "station_encoder": station_encoder
    }

    # íŒŒì¼ ì´ë¦„ì„ í†µí•© ëª¨ë¸ì„ì„ ë‚˜íƒ€ë‚´ë„ë¡ ë³€ê²½
    # .pkl.gz í™•ì¥ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì••ì¶•ë˜ì—ˆìŒì„ ëª…ì‹œ (ì„ íƒ ì‚¬í•­)
    path = f"models/lines_CardSubwayTime_model_{today}.pkl"

    # joblibì˜ compress ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ GZIP ì••ì¶• ë ˆë²¨ 7ë¡œ ì €ì¥
    # compress=('gzip', 7) ì ìš©
    joblib.dump(full_model_package, path, compress=('gzip', 7))

    # ì €ì¥ í›„ íŒŒì¼ í¬ê¸° ì¶œë ¥
    size_mb = os.path.getsize(path) / (1024 * 1024)
    print(f"Model and Encoders saved to {path}. Compressed size: {size_mb:.2f} MB")


# ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
def evaluate_model(model, X_test, y_test):
    print("ğŸ” ëª¨ë¸ í‰ê°€ ì¤‘...")
    pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, pred))
    print(f"[{datetime.today()}] RMSE: {rmse:.2f}")

    os.makedirs("logs", exist_ok=True)
    with open("logs/eval.log", "a") as f:
        f.write(f"[{datetime.today()}] Unified Model RMSE: {rmse:.2f}\n")


if __name__ == "__main__":
    print("ğŸ”¥ train.py ì‹œì‘ë¨ (í†µí•© í•™ìŠµ ëª¨ë“œ)")
    # ìµœê·¼ 9ê°œì›” ë°ì´í„°ë¡œ í•™ìŠµ
    months = get_recent_months(n_months=9)
    train_all_lines_and_stations(months)
